"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[1372],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>p});var n=a(7294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var i=n.createContext({}),c=function(e){var t=n.useContext(i),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(i.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,l=e.originalType,i=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),m=c(a),p=o,g=m["".concat(i,".").concat(p)]||m[p]||u[p]||l;return a?n.createElement(g,r(r({ref:t},d),{},{components:a})):n.createElement(g,r({ref:t},d))}));function p(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var l=a.length,r=new Array(l);r[0]=m;var s={};for(var i in t)hasOwnProperty.call(t,i)&&(s[i]=t[i]);s.originalType=e,s.mdxType="string"==typeof e?e:o,r[1]=s;for(var c=2;c<l;c++)r[c]=a[c];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},2991:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>i,contentTitle:()=>r,default:()=>u,frontMatter:()=>l,metadata:()=>s,toc:()=>c});var n=a(7462),o=(a(7294),a(3905));const l={sidebar_position:8,sidebar_label:"Local Cache Volumes "},r="Local Cache Volumes",s={unversionedId:"volumes/cache",id:"volumes/cache",title:"Local Cache Volumes",description:"It is very simple to run AI training applications using HwameiStor",source:"@site/docs/volumes/cache.md",sourceDirName:"volumes",slug:"/volumes/cache",permalink:"/docs/volumes/cache",draft:!1,editUrl:"https://github.com/hwameistor/hwameistor/edit/main/docs/docs/volumes/cache.md",tags:[],version:"current",sidebarPosition:8,frontMatter:{sidebar_position:8,sidebar_label:"Local Cache Volumes "},sidebar:"tutorialSidebar",previous:{title:"Eviction",permalink:"/docs/volumes/volume_eviction"},next:{title:"Local Volumes",permalink:"/docs/volumes/local"}},i={},c=[{value:"Install Dragonfly",id:"install-dragonfly",level:2},{value:"Verify <code>DataSet</code>",id:"verify-dataset",level:2},{value:"Create <code>DataSet</code>",id:"create-dataset",level:2},{value:"Create a PVC and bind it to dataset PV",id:"create-a-pvc-and-bind-it-to-dataset-pv",level:2},{value:"Create <code>StatefulSet</code>",id:"create-statefulset",level:2},{value:"Verify Nginx Pod",id:"verify-nginx-pod",level:2},{value:"Optional Scale Nginx out into a 3-node Cluster",id:"optional-scale-nginx-out-into-a-3-node-cluster",level:2}],d={toc:c};function u(e){let{components:t,...a}=e;return(0,o.kt)("wrapper",(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"local-cache-volumes"},"Local Cache Volumes"),(0,o.kt)("p",null,"It is very simple to run AI training applications using HwameiStor"),(0,o.kt)("p",null,"As an example, we will deploy an Nginx application by creating a local cache volume."),(0,o.kt)("p",null,"Before use, please ensure that Dragonfly has been installed in the cluster and relevant configurations have been completed."),(0,o.kt)("h2",{id:"install-dragonfly"},"Install Dragonfly"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Configure /etc/hosts according to the cluster"),(0,o.kt)("li",{parentName:"ol"},"Configure the default sc according to the selection")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-console"},' $ kubectl patch storageclass hwameistor-storage-lvm-hdd -p \'{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}\'\n')),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},"Install dragonfly using helm")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-console"},"$ helm repo add dragonfly https://dragonflyoss.github.io/helm-charts/\n$ helm install --create-namespace --namespace dragonfly-system dragonfly dragonfly/dragonfly --version 1.1.63\n")),(0,o.kt)("ol",{start:4},(0,o.kt)("li",{parentName:"ol"},"dragonfly-dfdaemon configuration")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-console"},"$ kubectl -n dragonfly-system get ds\n$ kubectl -n dragonfly-system edit ds dragonfly-dfdaemon\n\n...\nspec:\n      spec:\n        containers:\n        - image: docker.io/dragonflyoss/dfdaemon:v2.1.45\n       ...\n          securityContext:\n            capabilities:\n              add:\n              - SYS_ADMIN\n            privileged: true\n          volumeMounts:\n          ...\n            \n          - mountPath: /var/run\n            name: host-run\n          - mountPath: /mnt\n            mountPropagation: Bidirectional\n            name: host-mnt\n          ...\n      volumes:\n      ...\n      - hostPath:\n          path: /var/run\n          type: DirectoryOrCreate\n        name: host-run\n      - hostPath:\n          path: /mnt\n          type: DirectoryOrCreate\n        name: host-mnt\n      ... \n\n")),(0,o.kt)("ol",{start:5},(0,o.kt)("li",{parentName:"ol"},"Install the dfget client command line tool\nEach node executes:")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-console"},"$ wget https://github.com/dragonflyoss/Dragonfly2/releases/download/v2.1.44/dfget-2.1.44-linux-amd64.rpm\n$ rpm -ivh dfget-2.1.44-linux-amd64.rpm\n")),(0,o.kt)("ol",{start:6},(0,o.kt)("li",{parentName:"ol"},"Cancel the cluster default configuration sc")),(0,o.kt)("h2",{id:"verify-dataset"},"Verify ",(0,o.kt)("inlineCode",{parentName:"h2"},"DataSet")),(0,o.kt)("p",null,"Take minio as an example"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-console"},"apiVersion: datastore.io/v1alpha1\nkind: DataSet\nmetadata:\n  name: dataset-test\nspec:\n  refresh: true\n  type: minio\n  minio:\n    endpoint: Your service ip address:9000\n    bucket: BucketName/Dir  #Defined according to the directory level where your dataset is located\n    secretKey: minioadmin\n    accessKey: minioadmin\n    region: ap-southeast-2  \n")),(0,o.kt)("h2",{id:"create-dataset"},"Create ",(0,o.kt)("inlineCode",{parentName:"h2"},"DataSet")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-Console"},"$ kubectl apply -f dataset.yaml\n")),(0,o.kt)("p",null,"Confirm that the cache volume has been created successfully"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-Console"},"$ k get dataset\nNAME           TYPE    LASTREFRESHTIME   CONNECTED   AGE     ERROR\ndataset-test   minio                                 4m38s\n\n$ k get lv\nNAME                                       POOL                   REPLICAS   CAPACITY     USED        STATE   PUBLISHED           AGE\ndataset-test                               LocalStorage_PoolHDD              211812352                Ready                       4m27s\n\n$ k get pv\nNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                                                    STORAGECLASS                 REASON   AGE\ndataset-test                               202Mi      ROX            Retain           Available                                                                                                  35s\n\n")),(0,o.kt)("p",null,"The size of pv is determined by the size of your data set"),(0,o.kt)("h2",{id:"create-a-pvc-and-bind-it-to-dataset-pv"},"Create a PVC and bind it to dataset PV"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-Console"},"apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: hwameistor-dataset\n  namespace: default\nspec:\n  accessModes:\n  - ReadOnlyMany\n  resources:\n    requests:\n      storage: 202Mi  #dataset size\n  volumeMode: Filesystem\n  volumeName: dataset-test  #dataset name\n")),(0,o.kt)("p",null,"Confirm that the pvc has been created successfully"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-Console"},"\n## Verify  PVC\n\n$ k get pvc\nk get pvc\nNAME                 STATUS   VOLUME         CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nhwameistor-dataset   Bound    dataset-test   202Mi      ROX                           4s\n")),(0,o.kt)("h2",{id:"create-statefulset"},"Create ",(0,o.kt)("inlineCode",{parentName:"h2"},"StatefulSet")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-Console"},"$ kubectl apply -f sts-nginx-AI.yaml\n")),(0,o.kt)("p",null,"Please note the ",(0,o.kt)("inlineCode",{parentName:"p"},"claimName")," uses the name of the pvc bound to the dataset"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"    spec:\n      volumes:\n        - name: data\n          persistentVolumeClaim:\n            claimName: hwameistor-dataset\n")),(0,o.kt)("h2",{id:"verify-nginx-pod"},"Verify Nginx Pod"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-Console"},"$ kubectl get pod\nNAME               READY   STATUS            RESTARTS   AGE\nnginx-dataload-0   1/1     Running           0          3m58s\n$ kubectl  logs nginx-dataload-0 hwameistor-dataloader\nCreated custom resource\nCustom resource deleted, exiting\nDataLoad execution time: 1m20.24310857s\n")),(0,o.kt)("p",null,"According to the log, loading data took 1m20.24310857s"),(0,o.kt)("h2",{id:"optional-scale-nginx-out-into-a-3-node-cluster"},"[Optional]"," Scale Nginx out into a 3-node Cluster"),(0,o.kt)("p",null,"HwameiStor cache volumes support horizontal expansion of ",(0,o.kt)("inlineCode",{parentName:"p"},"StatefulSet"),". Each ",(0,o.kt)("inlineCode",{parentName:"p"},"pod")," of ",(0,o.kt)("inlineCode",{parentName:"p"},"StatefulSet")," will attach and mount a HwameiStor cache volume bound to the same dataset."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-console"},"$ kubectl scale sts/sts-nginx-AI --replicas=3\n\n$ kubectl get pod -o wide\nNAME               READY   STATUS    RESTARTS   AGE\nnginx-dataload-0   1/1     Running   0          41m\nnginx-dataload-1   1/1     Running   0          37m\nnginx-dataload-2   1/1     Running   0          35m\n\n\n$ kubectl logs nginx-dataload-1 hwameistor-dataloader\nCreated custom resource\nCustom resource deleted, exiting\nDataLoad execution time: 3.24310857s\n\n$ kubectl logs nginx-dataload-2 hwameistor-dataloader\nCreated custom resource\nCustom resource deleted, exiting\nDataLoad execution time: 2.598923144s\n\n")),(0,o.kt)("p",null,"According to the log, the second and third loading of data only took 3.24310857s and 2.598923144s respectively. Compared with the first loading, the speed has been greatly improved."))}u.isMDXComponent=!0}}]);